# ğŸ  FULLSTACK OPEN-SOURCE LAKEHOUSE PLATFORM

## Credit Card Fraud Detection - IEEE-CIS Dataset

Dá»± Ã¡n xÃ¢y dá»±ng há»‡ thá»‘ng **Data Lakehouse** hoÃ n chá»‰nh sá»­ dá»¥ng cÃ¡c cÃ´ng nghá»‡ mÃ£ nguá»“n má»Ÿ, triá»ƒn khai kiáº¿n trÃºc **Medallion** (Bronze â†’ Silver â†’ Gold) Ä‘á»ƒ phÃ¡t hiá»‡n gian láº­n tháº» tÃ­n dá»¥ng.

---

## âš¡ QUICK START - 2 CÃCH CHáº Y

### ğŸš€ CÃ¡ch 1: ONE COMMAND (Khuyáº¿n nghá»‹ - Tá»± Ä‘á»™ng hÃ³a hoÃ n toÃ n)

```bash
# Cháº¡y toÃ n bá»™ pipeline chá»‰ vá»›i 1 lá»‡nh
./scripts/run_full_pipeline.sh
```

**Káº¿t quáº£**: Bronze â†’ Silver â†’ Gold â†’ ClickHouse â†’ Superset Dashboard - **hoÃ n toÃ n tá»± Ä‘á»™ng!**

### ğŸ““ CÃ¡ch 2: Interactive Notebooks (Há»c táº­p & KhÃ¡m phÃ¡)

```bash
# 1. Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng
./scripts/start_lakehouse.sh

# 2. Má»Ÿ Jupyter: http://localhost:8888
# 3. Cháº¡y láº§n lÆ°á»£t cÃ¡c notebook:
#    - 01_bronze_layer.ipynb  â†’ Ingest raw data
#    - 02_silver_layer.ipynb  â†’ Clean & transform
#    - 03_gold_layer.ipynb    â†’ Analytics & aggregations
#    - 04_serving_layer.ipynb â†’ Copy to ClickHouse

# 4. Táº¡o Dashboard: http://localhost:8088 (admin/admin)

# Bonus: KhÃ¡m phÃ¡ Iceberg Time Travel
# 5. Cháº¡y 05_time_travel_demo.ipynb
```

ğŸ“– **Xem hÆ°á»›ng dáº«n chi tiáº¿t**: [SETUP_GUIDE.md](SETUP_GUIDE.md)

---

## ğŸ“‹ Má»¥c Lá»¥c

1. [YÃªu Cáº§u Há»‡ Thá»‘ng](#-yÃªu-cáº§u-há»‡-thá»‘ng)
2. [Kiáº¿n TrÃºc Há»‡ Thá»‘ng](#-kiáº¿n-trÃºc-há»‡-thá»‘ng)
3. [CÃ¡ch 1: Full Pipeline Script](#-cÃ¡ch-1-full-pipeline-script)
4. [CÃ¡ch 2: Jupyter Notebooks](#-cÃ¡ch-2-jupyter-notebooks)
5. [Iceberg Time Travel Demo](#-iceberg-time-travel-demo)
6. [Truy Cáº­p Services](#-truy-cáº­p-services)
7. [Cáº¥u TrÃºc ThÆ° Má»¥c](#-cáº¥u-trÃºc-thÆ°-má»¥c)
8. [Xá»­ LÃ½ Lá»—i](#-xá»­-lÃ½-lá»—i-thÆ°á»ng-gáº·p)

---

## ğŸ’» YÃªu Cáº§u Há»‡ Thá»‘ng

### Pháº§n cá»©ng tá»‘i thiá»ƒu

| ThÃ nh pháº§n | Tá»‘i thiá»ƒu | Khuyáº¿n nghá»‹ |
| ---------- | --------- | ----------- |
| **RAM**    | 8GB       | 16GB        |
| **Disk**   | 15GB      | 25GB        |
| **CPU**    | 4 cores   | 8 cores     |

### Pháº§n má»m cáº§n cÃ i

- **Docker** & **Docker Compose** v2.x
- **Python 3.x** (cho Superset auto-setup)
- **Git** (tÃ¹y chá»n)

### Kiá»ƒm tra Docker

```bash
docker --version        # Docker version 24.x+
docker compose version  # Docker Compose version v2.x+
```

---

## ğŸ— Kiáº¿n TrÃºc Há»‡ Thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LAKEHOUSE ARCHITECTURE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  MinIO  â”‚â”€â”€â”€â–¶â”‚  Spark  â”‚â”€â”€â”€â–¶â”‚   dbt   â”‚â”€â”€â”€â–¶â”‚ClickHouseâ”€â”€â”€â–¶â”‚Superset â”‚   â”‚
â”‚   â”‚(Storage)â”‚    â”‚(Compute)â”‚    â”‚(Transform)   â”‚(Serving)â”‚    â”‚(Visual) â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚        â”‚              â”‚              â”‚              â”‚              â”‚         â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                    â”‚                                         â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                     â”‚     Apache Iceberg          â”‚                          â”‚
â”‚                     â”‚     (Table Format)          â”‚                          â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                           MEDALLION ARCHITECTURE

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     BRONZE      â”‚â”€â”€â”€â–¶â”‚     SILVER      â”‚â”€â”€â”€â–¶â”‚      GOLD       â”‚
    â”‚   (Raw Data)    â”‚    â”‚   (Cleaned)     â”‚    â”‚  (Aggregated)   â”‚
    â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
    â”‚ â€¢ transactions  â”‚    â”‚ â€¢ silver_trans  â”‚    â”‚ â€¢ fraud_by_card â”‚
    â”‚ â€¢ identity      â”‚    â”‚ â€¢ silver_ident  â”‚    â”‚ â€¢ hourly_fraud  â”‚
    â”‚                 â”‚    â”‚                 â”‚    â”‚ â€¢ daily_summary â”‚
    â”‚                 â”‚    â”‚                 â”‚    â”‚ â€¢ kpi_summary   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                      â”‚                      â”‚
            â”‚                      â”‚                      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    SERVING LAYER    â”‚
                        â”‚    (ClickHouse)     â”‚
                        â”‚                     â”‚
                        â”‚  â€¢ Fast OLAP queriesâ”‚
                        â”‚  â€¢ Dashboard ready  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CÃ´ng nghá»‡ sá»­ dá»¥ng

| Táº§ng               | CÃ´ng nghá»‡       | MÃ´ táº£                          | Port       |
| ------------------ | --------------- | ------------------------------ | ---------- |
| **Storage**        | MinIO           | Object storage tÆ°Æ¡ng thÃ­ch S3  | 9000/9001  |
| **Catalog**        | Iceberg REST    | REST Catalog cho Iceberg       | 8181       |
| **Table Format**   | Apache Iceberg  | ACID transactions, Time Travel | -          |
| **Compute**        | Apache Spark    | Distributed data processing    | 8888/10000 |
| **Transformation** | dbt             | Data transformation vá»›i tests  | -          |
| **Serving**        | ClickHouse      | OLAP database hiá»‡u nÄƒng cao    | 8123       |
| **Visualization**  | Apache Superset | Dashboard & BI                 | 8088       |

---

## ğŸš€ CÃ¡ch 1: Full Pipeline Script

### YÃªu cáº§u trÆ°á»›c khi cháº¡y

1. **Docker Ä‘ang cháº¡y**
2. **Data files cÃ³ sáºµn** trong `notebooks/data/`:
   - ğŸ“¥ Táº£i bá»™ dá»¯ liá»‡u tá»« Kaggle: **[IEEE-CIS Fraud Detection](https://www.kaggle.com/competitions/ieee-fraud-detection)**
   - Táº£i file zip, giáº£i nÃ©n vÃ  copy 2 file sau vÃ o thÆ° má»¥c `notebooks/data/`:
     - `train_transaction.csv` (590,540 records)
     - `train_identity.csv` (144,233 records)

### Cháº¡y Pipeline

```bash
cd /path/to/Lakehouse_Project

# Cháº¡y toÃ n bá»™ pipeline
./scripts/run_full_pipeline.sh
```

### CÃ¡c bÆ°á»›c tá»± Ä‘á»™ng thá»±c hiá»‡n

| Step | TÃªn            | MÃ´ táº£                                        | Thá»i gian |
| ---- | -------------- | -------------------------------------------- | --------- |
| 0    | Docker Stack   | Khá»Ÿi Ä‘á»™ng 7 containers + Thrift Server       | ~2 phÃºt   |
| 1    | Bronze Layer   | Ingest CSV â†’ Iceberg tables                  | ~2 phÃºt   |
| 2    | dbt run        | Transform Silver + Gold (10 models)          | ~1 phÃºt   |
| 3    | Serving Layer  | Copy Gold tables â†’ ClickHouse (8 tables)     | ~1 phÃºt   |
| 4    | Superset Setup | Táº¡o Database + Datasets + Charts + Dashboard | ~2 phÃºt   |

**Tá»•ng thá»i gian: ~8-10 phÃºt**

### Káº¿t quáº£ mong Ä‘á»£i

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ‰ PIPELINE HOÃ€N Táº¤T!                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š Káº¾T QUáº¢:
   âœ… Bronze Layer: Raw CSV â†’ Iceberg tables (demo.bronze.*)
   âœ… Silver Layer: Cleaned data (bronze_silver.*)
   âœ… Gold Layer: Analytics tables (bronze_gold.*)
   âœ… Serving Layer: ClickHouse tables (fraud_detection.*)

ğŸŒ TRUY Cáº¬P:
   ğŸ“Š Superset Dashboard: http://localhost:8088 (admin/admin)
   ğŸ“ MinIO Console:     http://localhost:9001 (admin/password123)
   ğŸ’» Jupyter:           http://localhost:8888
   ğŸ—„ï¸  ClickHouse:        http://localhost:8123
```

---

## ğŸ““ CÃ¡ch 2: Jupyter Notebooks

PhÆ°Æ¡ng phÃ¡p nÃ y cho phÃ©p báº¡n **há»c vÃ  khÃ¡m phÃ¡** tá»«ng bÆ°á»›c cá»§a pipeline má»™t cÃ¡ch trá»±c quan.

### BÆ°á»›c 1: Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng

```bash
cd /path/to/Lakehouse_Project

# Khá»Ÿi Ä‘á»™ng Docker stack + Thrift Server
./scripts/start_lakehouse.sh
```

### BÆ°á»›c 2: Má»Ÿ Jupyter Lab

Truy cáº­p: **http://localhost:8888**

### BÆ°á»›c 3: Cháº¡y cÃ¡c Notebooks theo thá»© tá»±

#### ğŸ“¥ Notebook 1: Bronze Layer (`01_bronze_layer.ipynb`)

**Má»¥c Ä‘Ã­ch**: Ingest dá»¯ liá»‡u thÃ´ tá»« CSV vÃ o Iceberg tables

**Ná»™i dung**:

- Khá»Ÿi táº¡o Spark Session vá»›i Iceberg
- Äá»c file CSV (transactions + identity)
- ThÃªm metadata columns (`_ingestion_time`, `_source_file`)
- Táº¡o Iceberg tables trong namespace `demo.bronze`

**Output**:

```
demo.bronze.transactions â†’ 590,540 records
demo.bronze.identity     â†’ 144,233 records
```

---

#### ğŸ”„ Notebook 2: Silver Layer (`02_silver_layer.ipynb`)

**Má»¥c Ä‘Ã­ch**: LÃ m sáº¡ch vÃ  chuáº©n hÃ³a dá»¯ liá»‡u

**Ná»™i dung**:

- Data cleaning (xá»­ lÃ½ null values)
- Data type standardization
- Feature engineering cÆ¡ báº£n
- Táº¡o tables trong namespace `demo.silver`

**Output**:

```
demo.silver.silver_transactions â†’ Cleaned transaction data
demo.silver.silver_identity     â†’ Cleaned identity data
```

> ğŸ’¡ **LÆ°u Ã½**: Notebook nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c thay tháº¿ báº±ng `dbt run` vá»›i models trong `dbt_project/models/silver/`

---

#### ğŸ“Š Notebook 3: Gold Layer (`03_gold_layer.ipynb`)

**Má»¥c Ä‘Ã­ch**: Táº¡o cÃ¡c báº£ng phÃ¢n tÃ­ch vÃ  aggregations

**Ná»™i dung**:

- Join Silver transactions + identity
- TÃ­nh toÃ¡n KPIs vÃ  metrics
- Táº¡o cÃ¡c aggregation tables cho reporting
- Táº¡o tables trong namespace `demo.gold`

**Output**:

```
demo.gold.daily_transaction_summary â†’ Tá»•ng há»£p theo ngÃ y
demo.gold.fraud_by_card_type        â†’ PhÃ¢n tÃ­ch theo loáº¡i tháº»
demo.gold.fraud_by_product          â†’ PhÃ¢n tÃ­ch theo sáº£n pháº©m
demo.gold.hourly_fraud_analysis     â†’ PhÃ¢n tÃ­ch theo giá»
demo.gold.high_risk_transactions    â†’ Giao dá»‹ch rá»§i ro cao
demo.gold.kpi_summary               â†’ Tá»•ng há»£p KPIs
```

> ğŸ’¡ **LÆ°u Ã½**: Notebook nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c thay tháº¿ báº±ng `dbt run` vá»›i models trong `dbt_project/models/gold/`

---

#### ğŸ“¤ Notebook 4: Serving Layer (`04_serving_layer.ipynb`)

**Má»¥c Ä‘Ã­ch**: Copy dá»¯ liá»‡u Gold sang ClickHouse Ä‘á»ƒ phá»¥c vá»¥ Dashboard

**Ná»™i dung**:

- Káº¿t ná»‘i ClickHouse qua clickhouse-driver
- Táº¡o database `fraud_detection` trong ClickHouse
- Copy toÃ n bá»™ Gold tables sang ClickHouse
- Tá»‘i Æ°u cáº¥u trÃºc tables cho OLAP queries

**Output**:

```
fraud_detection.fraud_by_card_type        â†’ 15 rows
fraud_detection.hourly_fraud_analysis     â†’ 24 rows
fraud_detection.fraud_by_product          â†’ 5 rows
fraud_detection.kpi_summary               â†’ 1 row
fraud_detection.daily_transaction_summary â†’ 182 rows
fraud_detection.high_risk_transactions    â†’ 10,000 rows
fraud_detection.fraud_by_day_of_week      â†’ 7 rows
fraud_detection.fraud_by_amount_category  â†’ 6 rows
```

---

### BÆ°á»›c 4: Táº¡o Dashboard trong Superset

1. Má»Ÿ: **http://localhost:8088**
2. ÄÄƒng nháº­p: `admin` / `admin`
3. VÃ o **Settings â†’ Database Connections â†’ + Database**
4. Chá»n **ClickHouse Connect**
5. Nháº­p connection string:
   ```
   clickhousedb://default:clickhouse123@clickhouse:8123/fraud_detection
   ```
6. **Test Connection** â†’ **Connect**
7. Táº¡o Datasets vÃ  Charts

---

## â° Iceberg Time Travel Demo

### Notebook 5: Time Travel (`05_time_travel_demo.ipynb`)

**Má»¥c Ä‘Ã­ch**: Trá»±c quan hÃ³a tÃ­nh nÄƒng **Time Travel** cá»§a Apache Iceberg

**TÃ­nh nÄƒng demo**:

#### 1. Query Historical Data

```sql
-- Xem dá»¯ liá»‡u táº¡i snapshot cá»¥ thá»ƒ
SELECT * FROM demo.bronze.transactions VERSION AS OF <snapshot_id>
```

#### 2. View Table History

```sql
-- Xem lá»‹ch sá»­ thay Ä‘á»•i cá»§a table
SELECT * FROM demo.bronze.transactions.history
```

#### 3. View Snapshots

```sql
-- Xem danh sÃ¡ch snapshots
SELECT * FROM demo.bronze.transactions.snapshots
```

#### 4. Rollback Table

```python
# Rollback vá» snapshot trÆ°á»›c Ä‘Ã³
spark.sql(f"""
    CALL demo.system.rollback_to_snapshot(
        'demo.bronze.transactions',
        {snapshot_id}
    )
""")
```

#### 5. Compare Snapshots

```python
# So sÃ¡nh 2 snapshots
old_data = spark.read.option("snapshot-id", old_snapshot).table("demo.bronze.transactions")
new_data = spark.read.option("snapshot-id", new_snapshot).table("demo.bronze.transactions")
```

**CÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng Time Travel**:

- ğŸ”„ **Data Recovery**: KhÃ´i phá»¥c dá»¯ liá»‡u sau khi xÃ³a nháº§m
- ğŸ“Š **Audit**: Xem dá»¯ liá»‡u táº¡i thá»i Ä‘iá»ƒm cá»¥ thá»ƒ
- ğŸ§ª **Testing**: So sÃ¡nh káº¿t quáº£ giá»¯a cÃ¡c versions
- ğŸ“ˆ **Analytics**: PhÃ¢n tÃ­ch xu hÆ°á»›ng thay Ä‘á»•i theo thá»i gian

---

## ğŸŒ Truy Cáº­p Services

| Service           | URL                   | Credentials             | MÃ´ táº£              |
| ----------------- | --------------------- | ----------------------- | ------------------ |
| **Superset**      | http://localhost:8088 | admin / admin           | Dashboard & BI     |
| **Jupyter Lab**   | http://localhost:8888 | -                       | Notebooks          |
| **MinIO Console** | http://localhost:9001 | admin / password123     | Object Storage UI  |
| **ClickHouse**    | http://localhost:8123 | default / clickhouse123 | OLAP Database      |
| **Spark UI**      | http://localhost:4040 | -                       | Spark Jobs Monitor |
| **Iceberg REST**  | http://localhost:8181 | -                       | Catalog REST API   |

---

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c

```
Lakehouse_Project/
â”œâ”€â”€ ğŸ“„ docker-compose.yml       # Docker services configuration
â”œâ”€â”€ ğŸ“„ README.md                # TÃ i liá»‡u chÃ­nh (file nÃ y)
â”œâ”€â”€ ğŸ“„ SETUP_GUIDE.md           # HÆ°á»›ng dáº«n chi tiáº¿t
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/               # Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_bronze_layer.ipynb   # Ingestion raw data
â”‚   â”œâ”€â”€ 02_silver_layer.ipynb   # Data cleaning
â”‚   â”œâ”€â”€ 03_gold_layer.ipynb     # Aggregations
â”‚   â”œâ”€â”€ 04_serving_layer.ipynb  # Copy to ClickHouse
â”‚   â”œâ”€â”€ 05_time_travel_demo.ipynb # Iceberg Time Travel
â”‚   â””â”€â”€ ğŸ“‚ data/                # CSV data files
â”‚       â”œâ”€â”€ train_transaction.csv
â”‚       â””â”€â”€ train_identity.csv
â”‚
â”œâ”€â”€ ğŸ“‚ dbt_project/             # dbt transformation
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â””â”€â”€ ğŸ“‚ models/
â”‚       â”œâ”€â”€ ğŸ“‚ silver/          # Silver layer models
â”‚       â”‚   â”œâ”€â”€ silver_transactions.sql
â”‚       â”‚   â”œâ”€â”€ silver_identity.sql
â”‚       â”‚   â””â”€â”€ schema.yml
â”‚       â””â”€â”€ ğŸ“‚ gold/            # Gold layer models
â”‚           â”œâ”€â”€ daily_transaction_summary.sql
â”‚           â”œâ”€â”€ fraud_by_card_type.sql
â”‚           â”œâ”€â”€ fraud_by_product.sql
â”‚           â”œâ”€â”€ hourly_fraud_analysis.sql
â”‚           â”œâ”€â”€ high_risk_transactions.sql
â”‚           â”œâ”€â”€ kpi_summary.sql
â”‚           â””â”€â”€ schema.yml
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                 # Utility scripts
â”‚   â”œâ”€â”€ run_full_pipeline.sh    # â­ Full automation script
â”‚   â”œâ”€â”€ start_lakehouse.sh      # Start Docker + Thrift Server
â”‚   â”œâ”€â”€ stop_lakehouse.sh       # Stop all services
â”‚   â”œâ”€â”€ run_dbt.sh              # Run dbt commands
â”‚   â”œâ”€â”€ bronze_layer.py         # Bronze ingestion script
â”‚   â”œâ”€â”€ serving_layer.py        # Serving layer script
â”‚   â”œâ”€â”€ setup_superset.py       # Superset auto-setup
â”‚   â””â”€â”€ create_namespaces.py    # Create Iceberg namespaces
â”‚
â””â”€â”€ ğŸ“‚ markdown/                # Additional documentation
    â””â”€â”€ 06_COMPLETE_USER_GUIDE_1.md
```

---

## ğŸ”§ Xá»­ LÃ½ Lá»—i ThÆ°á»ng Gáº·p

### 1. Docker khÃ´ng cháº¡y

```bash
# Kiá»ƒm tra Docker daemon
docker info

# Náº¿u lá»—i, khá»Ÿi Ä‘á»™ng Docker Desktop hoáº·c service
sudo systemctl start docker
```

### 2. Thiáº¿u data files

```bash
# Kiá»ƒm tra data files
ls -la notebooks/data/*.csv

# Cáº§n cÃ³:
# - train_transaction.csv
# - train_identity.csv
```

### 3. Thrift Server khÃ´ng khá»Ÿi Ä‘á»™ng

```bash
# Xem logs
docker exec spark-iceberg cat /opt/spark/logs/*HiveThriftServer2*.out | tail -50

# Restart Thrift Server
docker exec spark-iceberg /opt/spark/sbin/stop-thriftserver.sh
./scripts/start_lakehouse.sh
```

### 4. dbt connection failed

```bash
# Kiá»ƒm tra Thrift Server port
docker exec dbt python3 -c "import socket; s=socket.socket(); s.settimeout(2); print('OK' if s.connect_ex(('spark-iceberg', 10000))==0 else 'FAIL')"

# Test dbt connection
docker exec dbt dbt debug
```

### 5. ClickHouse connection failed

```bash
# Kiá»ƒm tra ClickHouse
curl "http://localhost:8123/?query=SELECT%201"

# Restart ClickHouse
docker restart clickhouse
```

### 6. Reset toÃ n bá»™ há»‡ thá»‘ng

```bash
# Dá»«ng vÃ  xÃ³a táº¥t cáº£ volumes
docker compose down -v

# Khá»Ÿi Ä‘á»™ng láº¡i tá»« Ä‘áº§u
./scripts/run_full_pipeline.sh
```

---

## ğŸ“š TÃ i Liá»‡u Bá»• Sung

- [SETUP_GUIDE.md](SETUP_GUIDE.md) - HÆ°á»›ng dáº«n chi tiáº¿t tá»«ng bÆ°á»›c
- [dbt_project/README.md](dbt_project/README.md) - dbt documentation
- [markdown/](markdown/) - CÃ¡c tÃ i liá»‡u khÃ¡c

---

## ğŸ‘¨â€ğŸ’» Author

Dá»± Ã¡n Ä‘Æ°á»£c xÃ¢y dá»±ng Ä‘á»ƒ demo kiáº¿n trÃºc **Data Lakehouse** sá»­ dá»¥ng hoÃ n toÃ n cÃ´ng nghá»‡ **Open Source**.

---

## ğŸ“„ License

MIT License - Sá»­ dá»¥ng tá»± do cho má»¥c Ä‘Ã­ch há»c táº­p vÃ  nghiÃªn cá»©u.
